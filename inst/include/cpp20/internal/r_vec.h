#ifndef CPP20_R_VECTOR_H
#define CPP20_R_VECTOR_H

#include <cpp20/internal/r_methods.h>
#include <cpp20/internal/r_vec_utils.h>
#include <cpp20/internal/r_rtype_coerce.h>

namespace cpp20 {

template<RVal T>
struct r_vec {

  r_sexp sexp = r_null;
  using data_type = T;

  bool is_null() const noexcept {
    return sexp.is_null();
  }

  private:

  // Initialise read-only ptr to: 
  // SEXP - If T is `r_sexp` or `r_str`
  // T - Otherwise
  using ptr_t = std::conditional_t<RPtrWritableType<T>, unwrap_t<T>*, const SEXP*>;  
  ptr_t m_ptr = nullptr;

  void initialise_ptr(){
    if (!is_null()) {
      if constexpr (RPtrWritableType<T>) {
        m_ptr = internal::vector_ptr<T>(unwrap(sexp));
      } else if constexpr (any<T, r_sexp, r_sym>) {
        m_ptr = (const SEXP*) DATAPTR_RO(unwrap(sexp));
      } else if constexpr (is<T, r_str>){
        m_ptr = (const SEXP*) STRING_PTR_RO(unwrap(sexp));
      }
    }
  }
      
  public:

  // Constructor that wraps new_vec_impl<T>
  explicit r_vec(r_size_t n)
    : sexp(internal::new_vec_impl<std::remove_cvref_t<T>>(n))
  {
    initialise_ptr();
  }

  template<typename U>
  explicit r_vec(r_size_t n, U default_value)
    : r_vec(n)
  {
    fill(r_size_t(0), n, default_value);
  }
  
  r_vec(): r_vec(r_size_t(0)){}

  // Constructors from existing r_sexp/SEXP
  explicit r_vec(r_sexp s) : sexp(std::move(s)) {
    initialise_ptr();
  }

  explicit r_vec(SEXP s) : r_vec(r_sexp(s)) {}

  // // Copy constructor - copy sexp and re-initialise pointer
  // r_vec(const r_vec& other) : sexp(other.sexp) {
  //   initialise_ptr();
  // }

  // // Move constructor - move both sexp and pointer
  // r_vec(r_vec&& other) noexcept 
  //   : sexp(std::move(other.sexp)), m_ptr(other.m_ptr) 
  // {
  //   other.m_ptr = nullptr;
  // }

  // // Copy assignment - copy sexp and re-initialise pointer
  // r_vec& operator=(const r_vec& other) {
  //   if (this != &other) {
  //     sexp = other.sexp;
  //     m_ptr = nullptr;
  //     initialise_ptr();
  //   }
  //   return *this;
  // }

  // // Move assignment - move both sexp and pointer
  // r_vec& operator=(r_vec&& other) noexcept {
  //   if (this != &other) {
  //     sexp = std::move(other.sexp);
  //     m_ptr = other.m_ptr;
  //     other.m_ptr = nullptr;
  //   }
  //   return *this;
  // }

  // Implicit conversion to SEXP
  operator SEXP() const {
    return unwrap(sexp);
  }

  // Explicit conversion to r_sexp
  constexpr explicit operator r_sexp() const {
    return sexp;
  }

  // Direct pointer access
  ptr_t data() const {
    return m_ptr;
  }

  // Iterator support - begin + end
  ptr_t begin() {
      return data();
  }

  ptr_t end() {
      return data() + size();
  }

  r_size_t length() const noexcept {
    return sexp.length();
  }

  // Get size
  r_size_t size() const noexcept {
    return length();
  }

  r_str address() const {
    return sexp.address();
  }

  bool is_bare() const {
    return !Rf_isObject(sexp);
  }

  bool is_altrep() const {
    return static_cast<bool>(ALTREP(unwrap(sexp)));
  }

  // Get element (no bounds-check)
  template <CppIntegerType U>
  T get(U index) const {
    return T(m_ptr[index]);
  }

  // Set element (no bounds-check) - We use flexible template to be able to coerce it to an RVal
  template <CppIntegerType U, typename V>
  void set(U index, V val) {
      auto val2 = unwrap(cpp20::internal::as_r<T>(val));
      if constexpr (any<T, r_sexp, r_sym>){
        SET_VECTOR_ELT(sexp, index, val2);
      } else if constexpr (is<T, r_str>){
        SET_STRING_ELT(sexp, index, val2);
      } else {
        m_ptr[index] = val2;
      }
  }

  template <typename U>
  requires (any<U, r_int, r_int64>)
  r_vec<T> subset(const r_vec<U>& indices) const;

  r_vec<r_str> names() const {
    return r_vec<r_str>(Rf_getAttrib(sexp, symbol::names_sym));
  }

  void set_names(r_vec<r_str> names){
    if (names.is_null()){
      Rf_setAttrib(sexp, symbol::names_sym, r_null);
    } else if (names.length() != sexp.length()){
      abort("`length(names)` must equal `length(x)`");
    } else {
      Rf_namesgets(sexp, names);
    }
  }

  r_vec<r_lgl> is_na() const {
    r_size_t n = length();
    auto out = r_vec<r_lgl>(n);

    if constexpr (RPtrWritableType<T>){
      int n_threads = internal::calc_threads(n);
      if (n_threads > 1){
        OMP_PARALLEL_FOR_SIMD(n_threads)
        for (r_size_t i = 0; i < n; ++i){
          out.set(i, cpp20::is_na(get(i)));
        }
      } else {
        OMP_SIMD
        for (r_size_t i = 0; i < n; ++i){
          out.set(i, cpp20::is_na(get(i)));
        }
      }
    } else {
      for (r_size_t i = 0; i < n; ++i){
        out.set(i, cpp20::is_na(get(i)));
      }
    }

    return out;
  }

  r_size_t na_count() const {
    
    r_size_t n = length();
    r_size_t out(0);

    if constexpr (RPtrWritableType<T>){
      int n_threads = internal::calc_threads(n);

      if (n_threads > 1){
        #pragma omp parallel for simd num_threads(n_threads) reduction(+:out)
        for (r_size_t i = 0; i < n; ++i){
          out += cpp20::is_na(get(i));
        }
      } else {
        #pragma omp simd reduction(+:out)
        for (r_size_t i = 0; i < n; ++i){
          out += cpp20::is_na(get(i));
        }
      }
    } else {
      for (r_size_t i = 0; i < n; ++i){
        out += cpp20::is_na(get(i));
      }
    }

    return out;
  }

  bool any_na() const {
    return na_count() > 0;
  }

  bool all_na() const {
    return na_count() == length();
  }

  template <typename U>
  void fill(r_size_t start, r_size_t n, const U val){
    auto val2 = internal::as_r<T>(val);
    if constexpr (RPtrWritableType<T>){
      int n_threads = internal::calc_threads(n);
      auto* RESTRICT p_target = data();
      if (n_threads > 1) {
        OMP_PARALLEL_FOR_SIMD(n_threads)
        for (r_size_t i = 0; i < n; ++i) {
          p_target[start + i] = unwrap(val2);
        }
      } else {
        std::fill_n(p_target + start, n, unwrap(val2));
      }
    } else {
      for (r_size_t i = 0; i < n; ++i) {
        set(start + i, val2);
      }
    }
  }

  template <typename U1, typename U2>
  void replace(r_size_t start, r_size_t n, const U1 old_val, const U2 new_val){
    auto old_val2 = internal::as_r<T>(old_val);
    auto new_val2 = internal::as_r<T>(new_val);
    bool implicit_na_coercion = !cpp20::is_na(old_val) && cpp20::is_na(old_val2);
    if (!implicit_na_coercion){
      if constexpr (RPtrWritableType<T>){
        int n_threads = internal::calc_threads(n);
        auto *p_target = data();
        if (n_threads > 1) {
          OMP_PARALLEL_FOR_SIMD(n_threads)
          for (r_size_t i = 0; i < n; ++i) {
            r_lgl eq = p_target[start + i] == old_val2;
            if (eq.is_true()){
              p_target[start + i] = unwrap(new_val2);
            }
          }
        } else {
          OMP_SIMD
          for (r_size_t i = 0; i < n; ++i) {
            r_lgl eq = p_target[start + i] == old_val2;
            if (eq.is_true()){
              p_target[start + i] = unwrap(new_val2);
            }
          }
        }
      } else {
        for (r_size_t i = 0; i < n; ++i) {
          r_size_t idx = start + i;
          if (get(idx) == old_val2){
            set(idx, new_val2);
          }
        }
      }
    }
  }

  r_vec<T> resize(r_size_t n){
    r_size_t vec_size = length();
    if (n == vec_size){
      return *this;
    } else {
      auto resized_vec = r_vec<T>(n);
      r_size_t n_to_copy = std::min(n, vec_size);

      if constexpr (RPtrWritableType<T>){
        std::copy_n(this->begin(), n_to_copy, resized_vec.begin());
      } else {
        for (r_size_t i = 0; i < n_to_copy; ++i){
          resized_vec.set(i, this->get(i)); 
        }
      }
      return resized_vec;
    }
  }

  r_vec<T> rep_len(r_size_t n){

    r_size_t size = length();

    if (size == n){
      return *this;
    }

    auto out = r_vec<T>(n);

    if (size == 1){
      out.fill(0, n, get(0));
    } else if (n > 0 && size > 0){
      // Copy first block
      r_copy_n(out, *this, 0, std::min(size, n));

      if (n > size){
        // copy result to itself, doubling each iteration
        r_size_t copied = size;
        while (copied < n) {
          r_size_t to_copy = std::min(copied, n - copied);
          r_copy_n(out, out, copied, to_copy);
          copied += to_copy;
        }
    }
      // If length > 0 but length(x) == 0 then fill with NA
    } else if (size == 0 && n > 0){
      out.fill(0, n, na_value<T>());
    }
    return out;
  }

};

template <typename U>
requires (any<U, r_int, r_int64>)
r_vec<U> exclude_locs(r_vec<U> exclude, unwrap_t<U> xn) {

  using int_t = unwrap_t<U>;

  int_t n = xn;
  int_t m = exclude.length();
  int_t out_size, idx;
  int_t exclude_count = 0;
  int_t i = 0, k = 0;

  // Which elements do we keep?
  std::vector<bool> keep(n, true);

  for (int_t j = 0; j < m; ++j) {
    if (is_na(exclude.get(j))) continue;
    if (exclude.get(j) > 0){
      abort("Cannot mix positive and negative subscripts");
    }
    idx = -exclude.get(j);
    // Check keep array for already assigned FALSE to avoid double counting
    if (idx > 0 && idx <= n && keep[idx - 1] == 1){
      keep[idx - 1] = false;
      ++exclude_count;
    }
  }
  out_size = n - exclude_count;
  auto out = r_vec<r_int>(out_size);

  while(k != out_size){
    if (keep[i++] == true){
      out.set(k++, i);
    }
  }
  return out;
}

template <RVal T>
template <typename U>
requires (any<U, r_int, r_int64>)
inline r_vec<T> r_vec<T>::subset(const r_vec<U>& indices) const {

  using unsigned_int_t = std::make_unsigned_t<unwrap_t<U>>;

  unsigned_int_t
  xn = length(),
    n = indices.length(),
    k = 0,
    na_val = unwrap(na_value<U>()),
    j;

  auto out = r_vec<T>(n);

  for (unsigned_int_t i = 0; i < n; ++i){
    j = unwrap(indices.get(i));
    if (internal::between_impl<unsigned_int_t>(j, 1U, xn)){
      out.set(k++, get(--j));
    } 
    // If j > n_val then it is a negative signed integer
    else if (j > na_val){
      return subset(exclude_locs(indices, xn));
    } 
    else if (j != 0U){
      out.set(k++, na_value<T>());
    }
  }
  return out.resize(k);
}

namespace internal {

// A cleaner lambda-based alternative to
// using the canonical switch(TYPEOF(x))
//
// Pass both the SEXP and an auto variable inside a lambda
// and visit_vector() will assign the auto variable to the correct vector
// Then simply deduce its type (via decltype) for further manipulation
// To be used in a lambda
// E.g. visit_vector(x, [&](auto x_vec) {})

// One must account for objects like `NULL` and non-vectors outwith this method

template <class F>
decltype(auto) visit_vector(SEXP x, F&& f) {
  switch (CPP20_TYPEOF(x)) {
  case LGLSXP:          return f(r_vec<r_lgl>(x));
  case INTSXP:          return f(r_vec<r_int>(x));
  case CPP20_INT64SXP: return f(r_vec<r_int64>(x));
  case REALSXP:         return f(r_vec<r_dbl>(x));
  case STRSXP:          return f(r_vec<r_str>(x));
  case VECSXP:          return f(r_vec<r_sexp>(x));
  case CPLXSXP:         return f(r_vec<r_cplx>(x));
  case RAWSXP:          return f(r_vec<r_raw>(x));
  default:              abort("`x` must be a vector");
  }
}

// Same as above but no run-time error, user must deal with non-vector input
template <class F>
decltype(auto) visit_maybe_vector(SEXP x, F&& f) {
  switch (CPP20_TYPEOF(x)) {
  case LGLSXP:          return f(r_vec<r_lgl>(x));
  case INTSXP:          return f(r_vec<r_int>(x));
  case CPP20_INT64SXP: return f(r_vec<r_int64>(x));
  case REALSXP:         return f(r_vec<r_dbl>(x));
  case STRSXP:          return f(r_vec<r_str>(x));
  case VECSXP:          return f(r_vec<r_sexp>(x));
  case CPLXSXP:         return f(r_vec<r_cplx>(x));
  case RAWSXP:          return f(r_vec<r_raw>(x));
  default:              return f(nullptr);
  }
}

}


template <RVal T>
inline void r_copy_n(r_vec<T> &target, r_vec<T> &source, r_size_t target_offset, r_size_t n){

  if constexpr (RPtrWritableType<T>){
    auto *p_source = source.data();
    auto *p_target = target.data();

    int n_threads = internal::calc_threads(n);
    if (n_threads > 1) {
      OMP_PARALLEL_FOR_SIMD(n_threads)
      for (r_size_t i = 0; i < n; ++i) {
        p_target[target_offset + i] = p_source[i];
      }
    } else {
      std::copy_n(p_source, n, p_target + target_offset);
    }
  } else {
    for (r_size_t i = 0; i < n; ++i) {
      target.set(target_offset + i, source.get(i));
    }
  }
}

// Compact seq generator as ALTREP, same as `seq_len()`
// inline r_vec<r_int> compact_seq_len(r_size_t n){
//   if (n < 0){
//     abort("`n` must be >= 0");
//   }
//   if (n == 0){
//     return r_vec<r_int>();
//   }
//   r_sexp colon_fn = fn::find_pkg_fun(":", "base", false);
//   r_sexp out = fn::eval_fn(colon_fn, env::base_env, 1, n);
//   return r_vec<r_int>(out);
// }

}

#endif
